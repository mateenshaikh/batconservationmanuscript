---
title: "batman uscript code"
output:
  html_document:
    code_folding: show
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: true
    number_sections: true
    theme: lumen
    highlight: pygments
date: "`r Sys.Date()`"
---

<!--

    For figure 6.1 boxplots, we should only include the top 20 data deficient <NA> species. Realized that it also included species for whom we already have a conservation category.
 done
 
    Can we run a test to ask how well our model predicts the actual risk category. Regression?
 
    Let‚Äôs switch the figure with the Cis to a table with the mean and 95% CI
    10.1; avg estimate is now first column
 
    For the categorical variables, the proportion data figures look great, we want to use those. Also need one for island/mainland
    Sectoion 11.3 
 
    For the continuous variables (min temp of coldest month, area km), is there a better figure we can include or should we just keep the scatterplot we have in there now? maybe a boxplot with conservation category on the x and temp/area km on the y? We‚Äôre not sure how best to represent the data.
 
    Does it make sense to adjust the scores so that the top predicted score is set at 5 (as an example)?
 
    Are we going to leave the old analysis that Mat did (with no missing data) or are we going to replace those with the imputation approach that has species with missing data? 

 
-->

```{r setup, include=FALSE}
#  setwd("~/../../Dropbox/tru/research/bat/")
#  setwd("~/Dropbox/tru/research/bat/")
knitr::opts_chunk$set(
  echo = TRUE,
  cache=F,
  class.source = "foldable"
)
```
```{r klippy, echo=FALSE, include=TRUE}
klippy::klippy()
```

# Load prereq libraries

```{r,message=F,warning=F}
library(knitr)
library(phytools)
library(geiger)
library(mice)
library(nlme)  #for gls
```


# Load tree/data and modify

### Load in the traits and tree.

```{r}
name.data=read.csv("Bat.Data.Current.csv",stringsAsFactors = T)    
  rownames(name.data)=name.data$Species

bat.tree=read.nexus("bigbattree.tre")
```



### Delete irrelephant stuff üêò

Delete species from the each of the tree and traits not found in the other

```{r}
extraSpecies = name.check(bat.tree,name.data)

#delete from tree
bat.tree  = drop.tip(bat.tree,extraSpecies$tree_not_data) 

#delete from traits
name.data = name.data[-match(extraSpecies$data_not_tree,name.data$Species),]

name.check(bat.tree,name.data)
```

### Rescale variables.


The area being such large numbers overwhlems other smaller numbers in some, calculations, so converting to `Area.mkm` (area in mega meters or million sq km instead of just Area in sq km.)
```{r}
name.data=data.frame(name.data,Area.mkm=name.data$Area.km/10^6)
```

### capitalize some variables

```{r,eval=T}
levels(name.data$Habitats)[levels(name.data$Habitats)=="Savan"]<-"Savanna"
levels(name.data$Simple.Habitats)[levels(name.data$Simple.Habitats)=="Savan"]<-"Savanna"
name.data$Simple.Primary.diet <-  stringr::str_to_title(name.data$Simple.Primary.diet)
name.data$Primary.diet <- as.factor( stringr::str_to_title(name.data$Primary.diet))
name.data$Island.mainland.classification <-as.factor(  stringr::str_to_title(name.data$Island.mainland.classification))
```

### Collapse some other variables


```{r habs,fig.width=10,class.source = 'fold-hide'}
table(name.data$Habitats,name.data$Simple.Habitats)
```
In Habitat, some  variables have low numbers below 10 (arbitrary threshold), so we'll group them together so that standard errors are reasonably estimated. 


```{r}
collapsed.Habitats = as.character(name.data$Habitats)
collapsed.Habitats[collapsed.Habitats=="Unknown"]=NA

aquatic = match(collapsed.Habitats,c("Artificial/Aquatic","Marine","Wetlands"))
collapsed.Habitats[!is.na(aquatic)]="Aquatic"

otheropen = match(collapsed.Habitats,c("Desert","Grassland"))
collapsed.Habitats[!is.na(otheropen)]="OtherOpen"


name.data=data.frame(name.data,collapsed.Habitats=as.factor(collapsed.Habitats))

name.data=data.frame(name.data,X.centroid.abs=abs(name.data$X.centroid))
```


```{r,class.source='fold-hide'}
table(name.data$Habitats,collapsed.Habitats)

```

Next, I'm going to transform the altitudinal data. We initially found the max/min values had opposite signs and it could be having wider/narrower altitude bands was really at work so instead of max/min, we create a location (middle point of altitude) and range (from the middle) variable.


```{r}
Altitude.mid.m = with(name.data,(Altitudil.range.upper.m+Altitudil.range.lower.m)/2)
Altitude.range.m = with(name.data,Altitudil.range.upper.m-Altitudil.range.lower.m)

name.data=data.frame(name.data,Altitude.mid.m,Altitude.range.m)
```






```{r,results='hide'}

varsToUse = c(
  "Conservation.category.numeric",
  "collapsed.Habitats",
  "Altitude.mid.m","Altitude.range.m",
  "Forearm.avg.mm","Head.body.avg.mm","Y.centroid.abs",
  "Temp.annual.range",
  "Temp.seasonality","Max.temp.warmest.month","Isothermality",
  "Simple.Primary.diet",#"Primary.diet" , 
  "weight.avg.g" , 
  "Island.mainland.classification" , 
  "Min.temp.coldest.month" , 
  "Annual.precip." ,
  "Area.mkm"  #rather than Area.km
)
sort(names(name.data));varsToUse[is.na(match(varsToUse,names(name.data)))]
 modelVariables = name.data[,varsToUse]
                                  
Species = rownames(modelVariables)

(propmissing=apply(modelVariables,2,is.na) |> colMeans())
```

From the above, the body measurements are clearly correlated. For the analysis, I'll just use the bold one

 - **weight.avg.g**
 - Forearm.avg.mm
 - Head.body.avg.mm.


Similarly, a variety of the temperature variables are highly correlated so we'll just keep  Max.temp.warmest.month.

```{}

```

 - **Max.temp.warmest.month**
 - Temp.seasonality
 - Y.centroid.abs
 - Temp.annual.range
 - Isothermality
 - Min.temp.coldest.month

 
```{r}
colsToRemove = c("Forearm.avg.mm","Head.body.avg.mm",
                 "Y.centroid.abs",
                 "Temp.seasonality",
                 "Isothermality",
                 "Temp.annual.range",
                 "Min.temp.coldest.month"
                 #"Max.temp.warmest.month"
                 )
indicesOfColsToremove = match(colsToRemove,names(modelVariables))
  modelVariables = modelVariables[,-indicesOfColsToremove]
```





# Impute missing data

We only need to impute the variables that have a proportion of missing that's greater than zero. The default method is Predictive Mean Matching (PMM) which is hot-deck imputation or like a nearest neighbour approach. For every value we're missing, some "similar" observation's corresponding value is used. Note: it specifically does not always take the most similar (but more similar ones are more likely to be selected). That way, if when we impute many times, we do actually obtain a variety of values, with more sensible ones more often, so we get some randomness. This will be our way of introducing variability due to missingness (in addition to usual  variability due to randomness we base p-values and such off of).


```{r doImputations,results='hide'}
nimp = 20        #number of imputations/complete datasets to create
set.seed(2022)   #so that if we rerun this we get the same datasets


missingResp = is.na(name.data$Conservation.category.numeric)

cltype = ifelse(Sys.info()["sysname"]=="Windows","PSOCK","FORK")

traits.mice.abstract = parlmice(data = modelVariables, m = nimp,ncore=parallel::detectCores(),cl.type = cltype)
#traits.mice.abstract = mice(data = modelVariables, m = nimp)
traits.mice.abstract$loggedEvents 
new.traits.list = complete(traits.mice.abstract,action="all")
new.traits.list.complete = lapply(new.traits.list,function(ntl)ntl[!missingResp,])
```

The `loggedEvents` line is to see what the warnings are. In our case, I think it means the that habitat is almost constant  and taken out of imputation for the corresponding dep variables. You can view it by the line `traits.mice.abstract$loggedEvents` (not shown).


# Create Models

The variable `new.traits.list` is now a list of imputed datasets. We'll do all our analyses on all these data sets and combine the results for an estimate as well as a sense of variability. We'll create two functions for this first (one for the gls and one for plain lm). In the end we'll create plain linear models, and GLS models on the imputed data and the complete data (in all four combinations).

```{r createFunctions,class.source = 'fold-hide'}
#Create a helper function that makes a single gls model for a given complete data set
fitFullModel.collapsedhabitats = function(new.traits.i){
  Species = rownames(new.traits.i)
  new.traits.i=data.frame(Species=rownames(new.traits.i),new.traits.i)
  Full.Models <-gls(Conservation.category.numeric~ . -Species,data = new.traits.i,
                    correlation = corBrownian(phy = bat.tree,form=~Species), 
                    method = "ML")
}
fitFullModel.simplehabitats = function(new.traits.i){
  Species = rownames(new.traits.i)
  new.traits.i=data.frame(Species=rownames(new.traits.i),new.traits.i)
  Full.Models <-gls(Conservation.category.numeric~ 
                      Simple.Habitats + 
                      Simple.Primary.diet + 
                      weight.avg.g + 
                      Island.mainland.classification + 
                      Min.temp.coldest.month +  
                      Annual.precip. + 
                      Area.mkm,
                    correlation = corBrownian(phy = bat.tree,form=~Species), 
                    data = new.traits.i, 
                    method = "ML")
}
fitFullModel.habitats = function(new.traits.i){
  Species = rownames(new.traits.i)
  new.traits.i=data.frame(Species=rownames(new.traits.i),new.traits.i)
  Full.Models <-gls(Conservation.category.numeric~.,
                    correlation = corBrownian(phy = bat.tree,form=~Species), 
                    data = new.traits.i, 
                    method = "ML")
}


```
To parallelize the code, we can use the following lines. Note, the first line (not run) is short but only works on mac/linux. The second chunk works on all operating systems.


```{r parallizeAndRunmaclinux,results='hide',class.source = 'fold-hide'}
#this line should be parallelized if you can. 
#e.g., on linux/mac you can use forking (takes same amt of time, just fewer lines of code)
#     library(parallel)
#     imputedModelsGLS = mclapply(new.traits.list,fitFullModel,mc.cores=detectCores())


```
```{r parallizeAndRun,results='hide',class.source = 'fold-hide'}

#code for windows parallelization
library(parallel)
mclapp=function(X,FUN,...)parallel::mclapply(X,FUN,mc.cores=parallel::detectCores(),...)
mcsapp=function(X,FUN,...)simplify2array(mclapp(X,FUN,...))

cl=makePSOCKcluster(detectCores())
clusterExport(cl,varlist=c("bat.tree"))
clusterEvalQ(cl,c(
  library(ape),library(nlme)
  )
)
imputedModelsGLS.collapsed = parLapplyLB(cl,new.traits.list,fitFullModel.collapsedhabitats)
imputedModelsGLS.collapsed.complete = parLapplyLB(cl,new.traits.list.complete,fitFullModel.collapsedhabitats)
#imputedModelsGLS.simple = parLapplyLB(cl,new.traits.list,fitFullModel.simplehabitats)
#imputedModelsGLS.habitats = parLapplyLB(cl,new.traits.list,fitFullModel.habitats)
stopCluster(cl)

imputedModelsGLS=imputedModelsGLS.collapsed
imputedModelsGLS.complete=imputedModelsGLS.collapsed.complete

```



Across all the imputations, I'm going to get the average estimated conservation status, and compare it against the known ones and show that in boxplots.


# Analysis

### Helper variables

```{r helpervariables,class.source = 'fold-hide'}

imputedGLS.residuals = sapply(imputedModelsGLS, function(mod)mod$residuals)
imputedGLS.fitted    = sapply(imputedModelsGLS, function(mod)mod$fitted)



averagePredictedStatus.imputedgls = rowMeans(imputedGLS.fitted)

actualStatus = name.data$Conservation.category.numeric
knownSpecies = !is.na(actualStatus)
completeCases = complete.cases(name.data)

 knownPredictedStatuses=
   data.frame(actual=actualStatus[knownSpecies],predicted =averagePredictedStatus.imputedgls[knownSpecies],mod="gls",dataset="imputed")

knownPredictedStatuses$actual=as.factor(knownPredictedStatuses$actual)


```


```{r,eval=F}

imputedGLS.fitted.complete    = sapply(imputedModelsGLS.complete, function(mod)mod$fitted)

apply(
  (imputedGLS.fitted.complete-imputedGLS.fitted[!missingResp,])
,1,IQR) |> |> (`/`)(2)|>round(2) |> sort()
```





## Boxplots of fitted/actual


```{r}
library(ggplot2)
ggplot(knownPredictedStatuses,aes(x=actual,y=predicted))+
  geom_boxplot(data = knownPredictedStatuses)+
    xlab("Known Conservation Category")+
  ylab("Fitted Conservation Cateogory Score")+
  ggtitle("Fitted Score vs Actual Conservation Category for Known Species")

```


# Comparison of the highest risk species (point estimates)


```{r}
allscores = data.frame(
  actual=name.data$Conservation.category.numeric,
  medianimputedGLS=apply(imputedGLS.fitted,1,median)
)

ord = order(allscores$medianimputedGLS,decreasing=T)

topEstimates = (allscores[ord,])
head(topEstimates,20)


```

## Boxplots of highest GLS estimates (for missing Status)

```{r,class.source = 'fold-hide'}
require(reshape2)
top=1:20

missing = is.na(allscores$actual)

missingScores = allscores[missing,]
missingImputedGLS.fitted = imputedGLS.fitted[missing,]




ord = order(missingScores$medianimputedGLS,decreasing=T)
topEstimates = (missingScores[ord,])
ordtop = rev(ord[top])

imputeddf = melt(missingImputedGLS.fitted[ordtop,],varnames=c("Species","dataset"))
imputeddf[,2]="imputedgls"

imputeddf$dataset=as.factor(imputeddf$dataset)


spacedSpecies = sapply(strsplit(as.character(imputeddf$Species),"_"),paste,collapse=" ") 
imputeddf=data.frame(imputeddf,spacedSpecies=spacedSpecies)

#head(imputeddf)

ggplot(imputeddf,aes(x=reorder(spacedSpecies,value,FUN=median),y=value))+
  geom_boxplot()+
  ylab("Fitted Conservation Category Score")+ggtitle("Distributions of Top Fitted Conservation Category Scores by Median")+theme(plot.title = element_text(size = 10))+xlab("Species")+
  theme(axis.text.y = element_text(face = "italic"))+
  coord_flip()


```






# Conservation Category Scores by species

```{r}
imputedEstimates=data.frame(
  glsestimate=rowMeans(imputedGLS.fitted),
  actual = as.factor(name.data$Conservation.category.numeric),
  row.names=Species)

## habitat, diet, island mainland, imn temp coldest month, area.
ordofvars = match(row.names(imputedEstimates),rownames(modelVariables))
head(ordofvars)

imputedEstimates2 = data.frame(imputedEstimates,modelVariables[ordofvars,])
```
### Highest Scores
```{r}
imputedEstimates2[order(imputedEstimates2$glsestimate,decreasing=T)[1:40],]
```
### Lowest Scores
```{r}
imputedEstimates2[order(imputedEstimates2$glsestimate,decreasing=F)[1:40],]
```


# Summary info about missing data
```{r missingvars}
propmissing=apply(modelVariables,2,is.na) |> colMeans()
kable(as.data.frame(propmissing))
```

```{r completecases}

missingPredictors = !complete.cases(modelVariables[,-1])
missingResponse   = modelVariables[,1] |> is.na()

(missingTable = table(missingPredictors,missingResponse)/length(missingPredictors)|> round(2))

incompletePredictors = missingTable[2,]|>sum()|> (`*`)(100)|>round(2)
incompleteTotally = (1-missingTable[1,1])|>(`*`)(100)|>round(2)
```

`r incompletePredictors`% of the predictor data contains at least one missing value and `r incompleteTotally`% of the species information (predictor data and conservation status) contains at least one missing value.


# Model variables

```{r pooledModels,echo=F,eval=F}
fits = with(data=traits.mice.abstract,exp =gls(Conservation.category.numeric~ 
                      collapsed.Habitats + 
                      Simple.Primary.diet + 
                      weight.avg.g + 
                      Island.mainland.classification + 
                      Min.temp.coldest.month +  
                      Annual.precip. + 
                      Area.mkm,
                    correlation = corBrownian(phy = bat.tree,form=~Species), 
                  method = "ML")
)
```
The summary of the model estimates (not including the standard errors) are shown below are shown below.

```{r modelpooling,fig.height=10}

summaries = lapply(imputedModelsGLS,summary)


allEstimates = sapply(summaries,function(s) s$coefficients)

estimatesdf = reshape2::melt(allEstimates,value.name = c("estimate"),varnames=c("coefficient","imputationNumber"))

ggplot(estimatesdf,aes(x=coefficient,y=estimate))+
  geom_boxplot()+geom_hline(yintercept=0,color="red")+
  facet_wrap(coefficient~.,scales="free",ncol=1)+
   theme(strip.text.x = element_blank())+coord_flip()
```

# Frequentist summary tables


```{r,class.source='fold-hide'}
avgEstimate = data.frame(avgEstimate=apply(allEstimates,1,mean))

ttables = lapply(summaries,function(i)i$tTable)


stdErrs = sapply(ttables,function(i)i[,2])

#pool the standard error estimates

avgstderr = rowMeans(stdErrs)
vw = rowMeans(stdErrs^2)  #variance within
vb=  apply(stdErrs,1,var) #variance betwn (sample var)
vtot = vw+(1+1/(nimp))*vb

stdpooled = sqrt(vtot)

avgEstimate=apply(allEstimates,1,mean)

siglevel = 0.05

crit = -qnorm(siglevel/2)


lb = avgEstimate - crit*stdpooled
ub = avgEstimate + crit*stdpooled

teststat = avgEstimate/stdpooled

pval = 2*pnorm(-abs(teststat))

flags = c("****", "***", "**", "*", "")[findInterval(pval,c(0, 0.0001, 0.001, 0.01, 0.05, 1))]
```
## for slopes and significance

```{r}
kable(data.frame(avgEstimate,stdpooled,pval,flags))
```
## for intervals

```{r}

sig = (sign(lb)==sign(ub))|>ifelse(" *","")
kable(data.frame(estimate=avgEstimate,lb,ub,sig ))


```

## Interpreting the numbers

The significance of the slopes are all with respect to the <u>**reference**</u> variables. 

  - Habitat: Aquatic
  - Diet: Fruit

If a diet slope is positive, that means that diet **increases the conservation score compared to a Fruit-eater**. 

If a habitat slope is negative, that means it **decreases the conservation score compared to Aquatic**.



# Visual summaries
Looking at the visual summaries, it's not surprising that only the variables with variability in score come up significant.

## Category by Habitat

```{r class.source = 'fold-hide'}
subsettable = with(modelVariables,data.frame(collapsed.Habitats,Conservation.category.numeric))
subsettable=subsettable[complete.cases(subsettable),]
tab = addmargins(table(subsettable))

kable(tab)
```

```{r habsummary,fig.width=10,class.source = 'fold-hide'}
p=nrow(tab)-1
habitats = rownames(tab);habitats=habitats[1:p]#removes "sum"
sizes = paste( "( n =",tab[1:p,ncol(tab)],")")

size.df = data.frame(
  sizes=sizes,
  x=seq_len(p),
  y=rep(1.5,p)
)


ggplot(subsettable,aes(x=collapsed.Habitats,y=Conservation.category.numeric))+
  geom_boxplot()+xlab("Habitat")+ylab("Conservation Category")+
  geom_text(data=size.df,aes(label=sizes,y=y,x=x))+
  coord_flip()
#boxplot(modelVariables$Conservation.category.numeric~modelVariables$Habitats)

ggplot(subsettable,aes(x=collapsed.Habitats))+
  geom_bar(aes(fill=factor(Conservation.category.numeric)))+
  labs(fill="Conservation Category")+
  scale_fill_brewer(palette=7)+
  xlab("Habitat")+
  coord_flip()

size.df$x = habitats
size.df$y=0.8

ggplot(subsettable,aes(x=collapsed.Habitats))+
  geom_bar(aes(fill=factor(Conservation.category.numeric)),position="fill")+
  scale_fill_brewer(palette=7)+xlab("Habitat")+ylab("Known Conservation Category")+
  labs(fill="Conservation Category")+
  ylab("Proportion")+
  xlab("Habitat")+
  geom_text(data=size.df,aes(label=sizes,y=y,x=x))+
  coord_flip()

```

## Category by Diet

```{r class.source = 'fold-hide'}
subsettable = with(modelVariables,data.frame(Simple.Primary.diet,Conservation.category.numeric))
subsettable=subsettable[complete.cases(subsettable),]
tab = addmargins(table(subsettable))

kable(tab)

```

```{r dietsummary,fig.width=10,eval=T, class.source = 'fold-hide'}
p=nrow(tab)-1
diets = rownames(tab);diets=diets[1:p]#removes "sum"
sizes = paste( "( n =",tab[1:p,ncol(tab)],")")

size.df = data.frame(
  sizes=sizes,
  x=seq_len(p),
  y=rep(1.5,p)
)


ggplot(subsettable,aes(x=Simple.Primary.diet,y=Conservation.category.numeric))+
  geom_boxplot()+xlab("Habitat")+ylab("Known Conservation Category")+
  geom_text(data=size.df,aes(label=sizes,y=y,x=x))+
  coord_flip()
#boxplot(modelVariables$Conservation.category.numeric~modelVariables$Habitats)

ggplot(subsettable,aes(x=Simple.Primary.diet))+
  geom_bar(aes(fill=factor(Conservation.category.numeric)))+
  scale_fill_brewer(palette=7)+
  labs(fill="Conservation Category")+
  xlab("Primary Diet")+
  coord_flip()

size.df$x = diets
size.df$y=0.8

ggplot(subsettable,aes(x=Simple.Primary.diet))+
  geom_bar(aes(fill=factor(Conservation.category.numeric)),position="fill")+
  scale_fill_brewer(palette=7)+
  ylab("Proportion")+
  xlab("Primary Diet")+
  geom_text(data=size.df,aes(label=sizes,y=y,x=x))+
  labs(fill="Conservation Category")+
  coord_flip()

```

## Category by Island/mainland

```{r class.source = 'fold-hide'}
subsettable = with(modelVariables,data.frame(Island.mainland.classification,Conservation.category.numeric))
subsettable=subsettable[complete.cases(subsettable),]
tab = addmargins(table(subsettable))

kable(tab)

```

```{r islandsummary,fig.width=10,eval=T, class.source = 'fold-hide'}
p=nrow(tab)-1
classification = rownames(tab);classification=classification[1:p]#removes "sum"
sizes = paste( "( n =",tab[1:p,ncol(tab)],")")

size.df = data.frame(
  sizes=sizes,
  x=seq_len(p),
  y=rep(1.5,p)
)


ggplot(subsettable,aes(x=Island.mainland.classification,y=Conservation.category.numeric))+
  geom_boxplot()+xlab("Classification")+ylab("Known Conservation Category")+
  geom_text(data=size.df,aes(label=sizes,y=y,x=x))+
  coord_flip()
#boxplot(modelVariables$Conservation.category.numeric~modelVariables$Habitats)

ggplot(subsettable,aes(x=Island.mainland.classification))+
  geom_bar(aes(fill=factor(Conservation.category.numeric)))+
  scale_fill_brewer(palette=7)+
  labs(fill="Conservation Category")+
  xlab("Classification")+
  coord_flip()

size.df$x = classification
size.df$y=0.8

ggplot(subsettable,aes(x=Island.mainland.classification))+
  geom_bar(aes(fill=factor(Conservation.category.numeric)),position="fill")+
  scale_fill_brewer(palette=7)+
  ylab("Proportion")+
  xlab("Classification")+
  geom_text(data=size.df,aes(label=sizes,y=y,x=x))+
  labs(fill="Conservation Category")+
  coord_flip()

```


## Category by elevation
```{r class.source = 'fold-hide'}
subsettable = with(modelVariables,data.frame(Altitude.mid.m,Conservation.category.numeric))
subsettable=subsettable[complete.cases(subsettable),]
tab = addmargins(table(subsettable))



p=nrow(tab)-1
classification = rownames(tab);classification=classification[1:p]#removes "sum"
sizes = paste( "( n =",tab[1:p,ncol(tab)],")")

size.df = data.frame(
  sizes=sizes,
  x=seq_len(p),
  y=rep(1.5,p)
)



#kable(tab)

ggplot(subsettable,aes(x=Altitude.mid.m,y=factor(Conservation.category.numeric)))+
   geom_boxplot()+xlab("Elevation Midpoint (m)")+ylab("Known Conservation Category")+
  coord_flip()
#boxplot(modelVariables$Conservation.category.numeric~modelVariables$Habitats)









subsettable = with(modelVariables,data.frame(Altitude.range.m,Conservation.category.numeric))
subsettable=subsettable[complete.cases(subsettable),]
tab = addmargins(table(subsettable))



p=nrow(tab)-1
classification = rownames(tab);classification=classification[1:p]#removes "sum"
sizes = paste( "( n =",tab[1:p,ncol(tab)],")")

size.df = data.frame(
  sizes=sizes,
  x=seq_len(p),
  y=rep(1.5,p)
)




ggplot(subsettable,aes(x=Altitude.range.m,y=factor(Conservation.category.numeric)))+
   geom_boxplot()+xlab("Elevation Range (m)")+ylab("Known Conservation Category")+
  coord_flip()
#boxplot(modelVariables$Conservation.category.numeric~modelVariables$Habitats)





```



## Category by Area
```{r class.source = 'fold-hide'}
subsettable = with(modelVariables,data.frame(Area.mkm,Conservation.category.numeric))
subsettable=subsettable[complete.cases(subsettable),]
tab = addmargins(table(subsettable))



p=nrow(tab)-1
classification = rownames(tab);classification=classification[1:p]#removes "sum"
sizes = paste( "( n =",tab[1:p,ncol(tab)],")")

size.df = data.frame(
  sizes=sizes,
  x=seq_len(p),
  y=rep(1.5,p)
)



#kable(tab)

ggplot(subsettable,aes(x=Area.mkm,y=factor(Conservation.category.numeric)))+
   geom_boxplot()+xlab("Area (million sq km)")+ylab("Known Conservation Category")+scale_x_log10()+coord_flip()
#boxplot(modelVariables$Conservation.category.numeric~modelVariables$Habitats)


```

## Category by Max temp
```{r class.source = 'fold-hide'}
subsettable = with(modelVariables,data.frame(Max.temp.warmest.month,Conservation.category.numeric))
subsettable[,1]=subsettable[,1]/12
subsettable=subsettable[complete.cases(subsettable),]
tab = addmargins(table(subsettable))


p=nrow(tab)-1
classification = rownames(tab);classification=classification[1:p]#removes "sum"
sizes = paste( "( n =",tab[1:p,ncol(tab)],")")

size.df = data.frame(
  sizes=sizes,
  x=seq_len(p),
  y=rep(1.5,p)
)



#kable(tab)

ggplot(subsettable,aes(x=Max.temp.warmest.month,y=factor(Conservation.category.numeric)))+
   geom_boxplot()+xlab("Maximum temperature of warmest month")+ylab("Known Conservation Category")+scale_x_log10()+coord_flip()
#boxplot(modelVariables$Conservation.category.numeric~modelVariables$Habitats)








```



## Category by Weight
```{r}
subsettable = with(modelVariables,data.frame(weight.avg.g,Conservation.category.numeric))
subsettable=subsettable[complete.cases(subsettable),]
tab = addmargins(table(subsettable))



p=nrow(tab)-1
classification = rownames(tab);classification=classification[1:p]#removes "sum"
sizes = paste( "( n =",tab[1:p,ncol(tab)],")")

size.df = data.frame(
  sizes=sizes,
  x=seq_len(p),
  y=rep(1.5,p)
)




ggplot(subsettable,aes(x=weight.avg.g,y=factor(Conservation.category.numeric)))+
   geom_boxplot()+xlab("Average weight (g)")+ylab("Known Conservation Category")+
  scale_x_log10()+coord_flip()
#boxplot(modelVariables$Conservation.category.numeric~modelVariables$Habitats)





```


# Tables

Tables of the highest fitted conservation statuses

### By highest median GLS estimates
```{r}
imputedEstimates[order(imputedEstimates$glsestimate,decreasing=T),]
```

### By actual conservation status
```{r}
imputedEstimates[order(imputedEstimates$actual,decreasing=T),]
```


# Continuous variables by conservation status

##  By area
```{r areasummary,fig.width=10,eval=T, class.source = 'fold-hide'}
subsettable = with(name.data,data.frame(Area.km,Conservation.category.numeric))
subsettable=subsettable[complete.cases(subsettable),]


ggplot(subsettable,aes(x=Area.km,y=Conservation.category.numeric,group=Conservation.category.numeric))+
  geom_boxplot()+xlab("Area (km)")+ylab("Known Conservation Category")+scale_x_continuous(trans='log10')
  # geom_text(data=size.df,aes(label=sizes,y=y,x=x))+
  #coord_flip()
#boxplot(modelVariables$Conservation.category.numeric~modelVariables$Habitats)


```

##  By temperature
```{r tempsummary,fig.width=10,eval=T, class.source = 'fold-hide'}

subsettable = with(name.data,data.frame(Min.temp.coldest.month,Conservation.category.numeric))
subsettable=subsettable[complete.cases(subsettable),]
subsettable[,1]=subsettable[,1]/30


ggplot(subsettable,aes(x=Min.temp.coldest.month,y=Conservation.category.numeric,group=Conservation.category.numeric))+
  geom_boxplot()+xlab("Coldest temp (¬∞C)")+ylab("Known Conservation Category")#+scale_x_continuous(trans='log10')
  # geom_text(data=size.df,aes(label=sizes,y=y,x=x))+
  #coord_flip()
#boxplot(modelVariables$Conservation.category.numeric~modelVariables$Habitats)

```

#   TypeI vs type II analsyis

In the code below, we try to estimate if a species is high-risk (positive) or low-risk (negative). We define high-risk as being category 4 or 5.

The type I error rate is the proportion of low-risk species being called high risk (accidental flags).

The type II error rate is the proportion of high-risk species being called low-risk (missing stuff).

I think we can approach it this way: decide what type II error rate we think is reasonable, and look to see if the corresponding type I error rate is acceptable.. 

```{r rocstuff, class.source = 'fold-hide',fig.height=5,fig.width=5}


obtain2x2 = function(k,residuals,fitted){ #k is the threshold
  precisionrecall = mcsapp(1:length(imputedModelsGLS),function(i){
    
    predictions  = fitted                  #   =yhat
    actualvalues = residuals+predictions   #  y=r+yhat
    
    predictedrisk = predictions >= k
    actuallyatrisk= actualvalues>=4
    
    tp = mean( predictedrisk &  actuallyatrisk)  
    tn = mean(!predictedrisk & !actuallyatrisk)
    fp = mean( predictedrisk & !actuallyatrisk)
    fn = mean(!predictedrisk &  actuallyatrisk)
    
    c(tp=tp,tn=tn,fp=fp,fn=fn)
  })
  rowMeans(precisionrecall)
}




geterrors = function(dat){
  dat=as.data.frame(dat)

  tpr = sensitivity = with(dat,tp/(tp+fn))
  tnr = specificity = with(dat,tn/(tn+fp))
  fpr =               with(dat,fp/(fp+tn))
  
  type1 = fpr
  type2 = with(dat,fn/(tp+fn))
  power = 1-type2

  ord = order(tpr)
#  tpr=tpr[order(tpr)]
#  tnr=tnr[order(tnr)]
  data.frame(type1=type1,type2=type2)
}

phylosig(bat.tree,name.data$Conservation.category.numeric,method="K")
phylosig(bat.tree,name.data$Conservation.category.numeric,method="lambda")

thresholds = seq(0,5,.05)

prs = mcsapp(thresholds,
             obtain2x2,
             residuals=imputedGLS.residuals,
             fitted=imputedGLS.fitted) |> 
  t() |> as.data.frame()


fitted = imputedGLS.fitted
actual = fitted+imputedGLS.residuals

fitted=fitted[knownSpecies,]
actual=actual[knownSpecies,]


require(pROC)

getroc = function(i) roc(actual[,i]>=4,fitted[,i],quiet=T)
getauc = function(roc)roc$auc[1]

rocs = mclapp(1:ncol(actual),getroc)
aucs = mcsapp(rocs,getauc)
boxplot(aucs,main="AUC across all imputations for known statuses",horizontal=F)

#print(dim(imputedGLS.fitted))

#via midpoint riemann sum



prsvalues = geterrors(prs)




#power = 1-prsvalues$type2
#prsvalues = data.frame(prsvalues,power)



plot(prsvalues$type2,prsvalues$type1,xlim=c(0,1),ylim=c(0,1),xlab="Type II error rate",lty=1,ylab="Type I error rate")
grid()

```



```{r class.source = 'fold-hide'}

cors = apply(imputedGLS.fitted,2,function(fits)
  cor(fits[knownSpecies],actualStatus[knownSpecies])
  )
boxplot(cors,horizontal=T,main="Correlation between y and yhat")
boxplot(cors^2,horizontal=T,main="Squared correlation between Correlation between y and yhat")



mlsmodels = function(new.traits.i){
  Species = rownames(new.traits.i)
  new.traits.i=data.frame(Species=rownames(new.traits.i),new.traits.i)
  Full.Models <-lm(Conservation.category.numeric~ 
                      collapsed.Habitats + 
                      Simple.Primary.diet + 
                      weight.avg.g + 
                      Island.mainland.classification + 
                      Min.temp.coldest.month +  
                      Annual.precip. + 
                      Area.mkm,
                    data = new.traits.i)
}

mlsmodels = function(new.traits.i){
  Species = rownames(new.traits.i)
  new.traits.i=data.frame(Species=rownames(new.traits.i),new.traits.i)
  Full.Models <-lm(Conservation.category.numeric~ 
                      collapsed.Habitats + 
                      Simple.Primary.diet + 
                      weight.avg.g + 
                      Island.mainland.classification + 
                      Min.temp.coldest.month +  
                      Annual.precip. + 
                      Area.mkm,
                    data = new.traits.i)
}


require(parallel)
#mlsmodels = mclapply(new.traits.list,mlsmodels,mc.cores=detectCores())


```
# Comparison with complete data
```{r class.source = 'fold-hide'}


#completegls = gls(Conservation.category.numeric~., 
                  #   correlation = corBrownian(phy = bat.tree,form=~Species), 
                  #   data = modelVariables, 
                  #   method = "ML",
                  # na.action=na.omit
                  # )


completelm = lm(Conservation.category.numeric~ .,
                    data = modelVariables)



yhat = completelm$fitted.values
y    = yhat + completelm$residuals
lmr2all=cor(y,yhat)^2


# yhat = completegls$fitted
# y    = yhat + completegls$residuals
# glsr2all=cor(y,yhat)^2

```
Using only complete data, the squared correlation between fitted and actual conservation statuses is `r round(lmr2all,3)` for the linear model and `r 0` for the GLS.


## How much each variable explains by itself
Just using 

```{r class.source = 'fold-hide'}
modmatrix = modelVariables
  # with(name.data,data.frame(Conservation.category.numeric,
  #                     collapsed.Habitats,
  #                     Simple.Primary.diet, 
  #                     weight.avg.g,
  #                     Island.mainland.classification,
  #                     Min.temp.coldest.month,
  #                     Annual.precip.,
  #                     Area.mkm))

r2value=function(i){
  df = modmatrix[,c(1,i)]
  mod = lm(Conservation.category.numeric~.,data=df)
  yhat = mod$fitted.values
  y    = yhat + mod$residuals
  round(cor(y,yhat)^2*100/lmr2all)
}

cols = 2:ncol(modmatrix)
explained = data.frame(names(modmatrix[,cols]),sapply(cols,r2value))
names(explained)=c("Var","Percent")
```

```{r class.source = 'fold-hide'}
print(explained)
```


